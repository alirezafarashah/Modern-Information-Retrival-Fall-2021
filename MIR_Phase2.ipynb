{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a39194",
   "metadata": {
    "id": "88a39194"
   },
   "source": [
    "<center>\n",
    "\n",
    "# فاز دوم پروژه\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2219990",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "     در صورت هرگونه سوال به ایمیل‌های زیر پیام داده یا از طریق سایر پلتفرم‌ها پیگیری کنید\n",
    "    \n",
    "[Sina Tavakkoli](mailto:stavakkoli1999@gmail.com)\n",
    "     <br>\n",
    "[Alireza Daqiq](mailto:alireza.daghigh1999@gmail.com)\n",
    "    \n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657af262",
   "metadata": {
    "id": "657af262"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "## I. خلاصه انجام پروژه\n",
    "\n",
    "در این تمرین, می‌خواهیم یک تصحیح‌کننده‌ی غلط‌املایی احتمالاتی بسازیم که غلط‌های موجود در کوئری را اصلاح کند.\n",
    "   ورودی ما در این مسئله, کوئری $R$ است و هدف پیدا کردن کوئری درست $Q$ است که احتمال $P(Q\\mid R)$ را بیشینه کند. \n",
    "    بر اساس قضیه‌ی بیز داریم :\n",
    "$$\n",
    "    P(Q\\mid R) = \\frac{P(R\\mid Q)P(Q)}{P(R)}\\propto P(R\\mid Q)P(Q).\n",
    "$$\n",
    "از آنجایی که هدف ما پیدا کردن $Q$یی است که عبارت $P(Q\\mid R)$ را بیشینه کند, تنها کافی‌ست که $P(R\\mid Q)P(Q)$ را بیشینه کنیم.\n",
    "    حال با توجه به چیزهایی که گفته شد, مصحح غلط‌املایی احتمالاتی ما باید چهار بخش داشته باشد:\n",
    "  1.  **مدل ‌زبانی.**(Language Model) \\\n",
    "      توزیع اولیه‌ی یونیگرام‌ها و بایگرام‌ها را حساب می‌کند. این کار به ما اجازه می‌دهد که $P(Q)$ حساب کنیم. ما از maximum-likelihood estimation استفاده می‌کنیم, که وقوع توکن یونیگرام و بایگرام‌ها را در training corpus برای تعیین کردن احتمالات اولیه می‌شمرد.\n",
    "  2. **مدل احتمال ویرایش.** (Edit Probability Model)\\\n",
    "      احتمال خطاهایی که ممکن است در یک کوئری اتفاق بیافتد را حساب می‌کند. این به ما اجازه می‌دهد که $P(R\\mid Q)$ را محاسبه کنیم. به طور خاص، این کامپوننت احتمال کرکترهایی را حساب می‌کند که در یک کوئری ترم به اشتباه حذف، درج، جایگزین یا ترنسپوز شده‌اند.\n",
    "  3. **تولیدکننده‌ی نامزدها.** (Candidate Generator)\\\n",
    "      کوئری خام $R$ که توسط کاربر ثبت شده است را می‌گیرد و نامزد‌های $Q$ را تولید می‌کند.\n",
    "  4. **امتیازدهنده‌ی نامزدها.** (Candidate Scorer)\\\n",
    "      موارد (1), (2) و (3) را برای محاسبه‌ی $Q^{*} = \\arg\\max_{Q}P(Q\\mid R)$ ترکیب می‌کند. یعنی برای هر $Q$ که توسط تولید‌کننده‌ی نامزدها تولید شده است، امتیازدهنده از مدل‌زبان برای محاسبه‌ی $P(Q)$ و از مدل احتمال ویرایش برای محاسبه‌ی $P(R\\mid Q)$ استفاده می‌کند و در نهایت $Q$ را انتخاب می‌کند که مقدار $P(Q)P(R\\mid Q)$ بیشینه می‌کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z3TkKKFXQSx6",
   "metadata": {
    "id": "Z3TkKKFXQSx6"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "## II. جزئیات پروژه\n",
    "\n",
    "\n",
    "  1. [تسک اول: تصحیح املا با استفاده از Uniform Edit Costs](#uniform)\n",
    "  2. [تسک دوم: تصحیح املا با استفاده از Empirical Edit Costs](#empirical)\n",
    "  3. [گزارش مکتوب](#written)\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb003c31",
   "metadata": {
    "id": "fb003c31"
   },
   "source": [
    "<a id=\"dataset\"></a>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "## III. دیتاست\n",
    "\n",
    "\n",
    "برای این تمرین, ما برای داده‌های تمرین و تست  از یکی از دیتا‌ست‌های دانشگاه استنفورد با اندکی تغییرات استفاده کردیم\n",
    "برای متون هم ازیکی از آزمایشگاه‌های این دانشگاه بهره بردیم.\n",
    "\n",
    "   <div dir=\"rtl\">\n",
    "   دیتاست از این <a href=\"https://drive.google.com/file/d/17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs/view?usp=sharing\"> لینک </a> قابل دسترسی است. آن‌را دانلود کرده و کنار notebook قرار دهید و سلول زیر را اجرا کنید . دیتاست شامل سه بخش زیر است:\n",
    "    </div>\n",
    "    <ul>\n",
    "       <li>  corpusها : در پوشه مربوط به آن ۱۰ فایل می‌بینید که هر خط هر فایل از یک مستند است. از tokenهای این بخش در ساخت model استفاده کنید</li>\n",
    "       <li> training set: شامل جفت‌هایی از عبارات غلط و درست‌ آنها که با حداکثر یک عدد که edit distanceآنهاست جدا شده‌اند</li>\n",
    "       <li>  dev set : در پوشه مربوطه سه فایل وجود دارد, ورژن عبارات با غلط املایی, ورژن صحیح آنها در gold.txt  و ورژن تصحیح شده توسط google در google.txt </li>\n",
    "    </ul>    \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64022bd",
   "metadata": {
    "id": "e64022bd",
    "outputId": "aa1b2799-ea60-4cf0-9340-e34a932e34f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import modules\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8056cf7a",
   "metadata": {
    "id": "8056cf7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data unzipped to MIR2-data...\n",
      "\n",
      "Directory Structure:\n",
      "MIR2-data\\\n",
      "  - corpus\\\n",
      "  - dev_set\\\n",
      "  - training_set\\\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "# go to this url and download dataset https://drive.google.com/file/d/17ukKiVAYtbBuL_zI8_2IhZ8uzxkMJdPs/view?usp=sharing\n",
    "data_dir = 'MIR2-data'\n",
    "\n",
    "# Unzip dataset\n",
    "with zipfile.ZipFile('{}.zip'.format(data_dir), 'r') as zip_fh:\n",
    "    zip_fh.extractall()\n",
    "print('Data unzipped to {}...\\n'.format(data_dir))\n",
    "\n",
    "# Print the directory structure\n",
    "print('Directory Structure:')\n",
    "print(data_dir + os.path.sep)\n",
    "for sub_dir in os.listdir(data_dir):\n",
    "    if not sub_dir.startswith('.'):\n",
    "        print('  - ' + sub_dir + os.path.sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130863a",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "در تغییر ساختار کد در هر بخش آزاد هستید, فقط خروجی‌ها باید مورد انتظار بوده و تغییر داده شده در گزارش مکتوب آورده شود\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764617ad",
   "metadata": {
    "id": "764617ad"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "<a id='uniform'></a>\n",
    "## IV. تسک اول:\n",
    "\n",
    "### IV.1. مدل‌زبان\n",
    "\n",
    "  حال می‌خواهیم یک مدل‌زبان برا پیشبینی $P(Q)$ از training corpusها بسازیم. رفتار ما با $P(Q)$ به صورت مجموعه‌ای از ترم‌های $(w_1, \\ldots, w_n)$ است که:\n",
    "  $$\n",
    "P(w_1, \\ldots, w_n) = P(w_1)P(w_2\\mid w_1)\\cdots P(w_n\\mid w_{n-1}),\n",
    "$$\n",
    "  که $P(w_1)$ در واقع احتمال یونیگرام ترم$w_1$  و $P(w_{i}\\mid w_{i-1})$ و احتمال بایگرام $(w_{i-1}, w_i)$ برای $i \\in \\{2, \\ldots, n\\}$ است.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7e86e",
   "metadata": {
    "id": "6cc7e86e"
   },
   "source": [
    "<div  style=\"direction:rtl\" >\n",
    "\n",
    "مدل‌زبان برای به دست آوردن احتمالات از MLE استفاده می کند:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  P_{\\text{MLE}}(w_i) & = \\frac{\\texttt{count}(w_i)}{T},\n",
    "  &\n",
    "  P_{\\text{MLE}}(w_i\\mid w_{i-1}) & = \\frac{\\texttt{count}((w_{i}, w_{i-1}))}{\\texttt{count}(w_{i-1})},\n",
    "\\end{align*}\n",
    "$$\n",
    "که $T$ تعداد کل توکن‌ها در corpus است و $\\texttt{count}$ تعداد یونیگرام‌ها و بایگرام‌هاست.\n",
    "\n",
    "برای به‌دست آوردن count برای یونیگرام‌ها و بایگرام‌ها در corpus، کد زیر را کامل کنید:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19b1385",
   "metadata": {
    "id": "e19b1385"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LanguageModel:\n",
    "\n",
    "    def __init__(self, corpus_dir='MIR2-data/corpus', lambda_=0.1):\n",
    "\n",
    "        self.lambda_ = lambda_\n",
    "        self.total_num_tokens = 0        # Counts total number of tokens in the corpus\n",
    "        self.unigram_counts = Counter()  # Maps strings w_1 -> count(w_1)\n",
    "        self.bigram_counts = Counter()   # Maps tuples (w_1, w_2) -> count((w_1, w_2))\n",
    "\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                with open(corpus_dir+'/'+str(i)+'.txt', 'r', encoding='utf-8') as f:\n",
    "                    for line in f:\n",
    "                        for word in line.split():\n",
    "                            self.unigram_counts[word] += 1\n",
    "                        wordss = line.split()\n",
    "                        for i in range(len(wordss)-1):\n",
    "                            self.bigram_counts[(wordss[i+1],wordss[i])] += 1  \n",
    "                            \n",
    "            except FileNotFoundError:\n",
    "                print(\"File not found\")\n",
    "        self.total_num_tokens = sum(self.unigram_counts.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd00ef9",
   "metadata": {
    "id": "9dd00ef9"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "   حال که تعداد یونیگرام‌ها و بایگرام‌ها را محاسبه کردیم، باید احتمال کوئری‌ها را نیز بسنجیم. قبل از ان به بایگرام‌هایی بپردازیم که هیچ‌گاه در corpus ندیدیم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbe094",
   "metadata": {
    "id": "a4bbe094"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "#### IV.1.2.  هموارسازی با استفاده از درون‌یابی ( Smoothing by Interpolation)\n",
    "\n",
    "مدل احتمال یونیگرام به عنوان مجموعه لغات ما هم خواهد بود. چون فرض می‌کنیم که کوئری ما از مستند corpus آمده است، درنتیجه در احتمالات یونیگرام خود نیازی به [هموارسازی لاپلاس](https://en.wikipedia.org/wiki/Additive_smoothing) نداریم، چون نامزدهای ما از همین لغت‌نامه آمده‌اند. اما حتی اگر دو کوئری ترم داشتیم که هردوی آن‌ها جزو کوئری زبان ما بودند، تضمینی نیست که بایگرام متناظر آن‌ها در training corpus وجود داشته باشند. برای مدیریت این پراکندگی داده ما احتمالات یونیگرام و بایگرام را برای به دست آوردن احتمال شرطی نهایی خود *درون‌یابی* می‌کنیم:\n",
    "$$\n",
    "P(w_2\\mid w_1) = \\lambda P_{\\text{MLE}}(w_2) + (1 - \\lambda)P_{\\text{MLE}}(w_2\\mid w_1).\n",
    "$$\n",
    "با قرار دادن یک مقدار کوچک به جای $\\lambda$ (برای مثال، 0.1) شروع می‌کنیم و سپس با تغییر این متغیر آزمون و خطا می‌کنیم تا دقت تصحیح ما در دیتاست توسعه بالاتر برود. توجه کنید که در این مورد برای دیتاست مورد نظر overﬁt نکنید. می‌توانید یک قسمت کوچک از داده‌های خود را برای tune کردن پارامترها نگه‌دارید.\n",
    "\n",
    "توابع زیر را برای کامل کردن کلاس `LanguageModel` بنویسید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92a780e",
   "metadata": {
    "id": "b92a780e"
   },
   "outputs": [],
   "source": [
    "# NOTE: Syntax on the following line just extends the `LanguageModel` class\n",
    "class LanguageModel(LanguageModel):\n",
    "    def get_unigram_logp(self, unigram):\n",
    "\n",
    "        try:\n",
    "            return math.log(self.unigram_counts[unigram]/self.total_num_tokens)\n",
    "        except:\n",
    "            return float('-inf')\n",
    "\n",
    "    def get_bigram_logp(self, w_1, w_2):\n",
    "        try:\n",
    "            return math.log(self.lambda_* (self.unigram_counts[w_2]/self.total_num_tokens) + \n",
    "                        (1-self.lambda_) * self.bigram_counts[(w_2,w_1)]/self.unigram_counts[w_1])\n",
    "        except:\n",
    "            return float('-inf')\n",
    "\n",
    "\n",
    "    def get_query_logp(self, query):\n",
    "\n",
    "        words = query.strip().split()\n",
    "        if len(words)==0:\n",
    "            return float('-inf')\n",
    "        p = 0 if words[0].isdigit() else self.get_unigram_logp(words[0])\n",
    "        for i in range(len(words)-1):\n",
    "            if words[i].isdigit():\n",
    "                continue\n",
    "            try:    \n",
    "                p += self.get_bigram_logp(words[i],words[i+1])\n",
    "            except:\n",
    "                p += 10**(-6)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273c3491",
   "metadata": {
    "id": "273c3491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num. unigrams(\"347071\")\n",
      "num. bigrams(\"4454471\")\n",
      "num. tokens(\"25498340\")\n",
      "P(\"stanford university\") == 0.003335533975682097\n",
      "P(\"stanford universit\") == 2.1364941294973931e-07\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Make sure your implementation passes the following sanity checks\n",
    "# Note: Constructing the language model could take 30 seconds or longer\n",
    "# We suggest using `tqdm` to track progress in your `LanguageModel.__init__` function.\n",
    "lm = LanguageModel()\n",
    "\n",
    "print('num. unigrams(\"{}\")'.format(len(lm.unigram_counts))) \n",
    "print('num. bigrams(\"{}\")'.format(len(lm.bigram_counts)))\n",
    "print('num. tokens(\"{}\")'.format(lm.total_num_tokens))\n",
    "\n",
    "5\n",
    "# Test a reasonable query with and without typos (you should try your own)!\n",
    "query_wo_typo = \"stanford university\" # write a query without typo\n",
    "query_w_typo = \"stanford universit\"  # write a query with typo\n",
    "\n",
    "p_wo_typo = math.exp(lm.get_query_logp(query_wo_typo))\n",
    "p_w_typo = math.exp(lm.get_query_logp(query_w_typo))\n",
    "print('P(\"{}\") == {}'.format(query_wo_typo, p_wo_typo))\n",
    "print('P(\"{}\") == {}'.format(query_w_typo, p_w_typo))\n",
    "if p_wo_typo <= p_w_typo:\n",
    "    print('Are you sure \"{}\" should be assigned higher probability than \"{}\"?'\n",
    "          .format(query_w_typo, query_wo_typo))\n",
    "    \n",
    "print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbed225",
   "metadata": {
    "id": "4cbed225"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### IV.2.  مدل احتمال ویرایش (Edit Probability Model)\n",
    "\n",
    "مدل احتمال ویرایش تلاش می‌کند تا مقدار $P(R\\mid Q)$ را محاسبه کند. برای یک کوئری نامزد ثابت $Q$، مدل احتمال ویرایش احتمالی را حساب می‌کند که یک کوئری خام احتمالا خطادار $R$ ثبت شده است. در این‌جا فاصله‌ی بین کوئری نامزد $Q$ و ورودی $R$ را با استفاده از [فاصله‌ی Damerau-Levenshtein](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance) مقداردهی می‌کنیم. در فاصله‌ی Damerau-Levenshtein، ویرایش‌های احتمالی برابرthe possible edits are **درج**، **حذف**، **جایگزینی** و **جابجایی**، که هرکدام شامل تک‌کرکترها به عنوان عملگر هستند. در پایین یک کلاس پایه برای `EditCostModel` را می‌بینید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786b119e",
   "metadata": {
    "id": "786b119e"
   },
   "outputs": [],
   "source": [
    "\n",
    "class BaseEditProbabilityModel:\n",
    "    def get_edit_logp(self, edited, original):\n",
    "        raise NotImplementedError  # Force subclass to implement this method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31bbaba",
   "metadata": {
    "id": "b31bbaba"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**نکته مهمی که باید بدانیم این‌است که تابع get_edit_logp با دو ورودی صدا زده می شود که edit-distance آنها یک است.** \n",
    "<br>همچنین خروجی نیازی به نرمال شدن ندارد که مجموع احتمالات کانید‌ها یک شود.\n",
    "\n",
    "</div>\n",
    "\n",
    "```python\n",
    "epm = EditProbabilityModelSubclass(...)  # You will define such a subclass later\n",
    "original = 'user'\n",
    "edited = 'usre'                      # Edited by transposing 'r' and 'e'\n",
    "score = epm.get_edit_logp(edited, original)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd0c23",
   "metadata": {
    "id": "46dd0c23"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "#### IV.2.1. مدل ویرایش Uniform-Cost\n",
    "\n",
    "ابتدا *uniform-cost edit model* را پیاده‌سازی می‌کنیم. این مدل محاسبه‌ی احتمال ویرایش را با فرض این که هر ویرایش در فاصله‌ی Damerau-Levenshtein احتمال یکسان دارد، ساده می‌کند. شما باید یک بازه از مقادیر را برای احتمال ویرایش uniform امتحان کنید، اما برای شروع، بازه‌ی 0.01 - 0.10 مناسب است. یک نکته‌ی مهم که باید در ساختن مدل خود به خاطر داشته باشید، این است که کوئری ورودی $R$ کاربر در اکثر مواقع صحیح است (*برای مثال،* $R = Q$). بنابراین باید یک احتمال ثابت بالا برای `edited == original` در نظر گرفته شود؛یک بازه‌ی معقول 0.90 - 0.95 است.\n",
    "\n",
    "مدل احتمال ویرایشی که در اینجا می‌سازید، زمانی که نامزدهای تصحیح کوئری را رتبه‌بندی می‌کنید استفاده خواهد شد. تولیدکننده‌ی این نامزدها (که در بخش بعدی توضیح داده شده‌ است) یک ویرایش در هر زمان انجام می‌دهد و هر وقت یک ویرایش در یک ترم انجام می‌دهد، مدل احتمال ویرایش را صدا می‌زند و log-probabilities را برای تغییرات multi-edit جمع می‌کند. بنابراین در این قسمت شما تنها باید احتمال `edited` را با توجه به این که این مورد **حداکثر یک ویرایش تا `original` فاصله دارد** حساب کنید. یعنی در اینجا `get_edit_logp` خیلی ساده خواهد بود.\n",
    "\n",
    "برای پیاده‌سازی مدل ویرایش uniform-cost کلاس زیر را کامل کنید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef111c1",
   "metadata": {
    "id": "eef111c1"
   },
   "outputs": [],
   "source": [
    "\n",
    "class UniformEditProbabilityModel(BaseEditProbabilityModel):\n",
    "    def __init__(self, edit_prob=0.05):\n",
    "\n",
    "        self.edit_prob = edit_prob\n",
    "\n",
    "    def get_edit_logp(self, edited, original):\n",
    "\n",
    "        if edited == original:\n",
    "            return math.log(1-self.edit_prob) \n",
    "        return math.log(self.edit_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3a180c",
   "metadata": {
    "id": "4b3a180c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "EDIT_PROB = 0.05\n",
    "epm = UniformEditProbabilityModel(edit_prob=EDIT_PROB)\n",
    "\n",
    "# Test a basic edit\n",
    "edited, original = 'usre', 'user'\n",
    "print(math.isclose(epm.get_edit_logp(edited, original), math.log(EDIT_PROB)))\n",
    "\n",
    "# Test a non-edit\n",
    "print( math.isclose(epm.get_edit_logp(original, original), math.log(1. - EDIT_PROB)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3802a",
   "metadata": {
    "id": "b3d3802a"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "### IV.3. تولیدکننده‌ی نامزدها \n",
    "\n",
    "تولیدکننده‌ی نامزدها یک کوئری خام $R$ که توسط کاربر ثبت شده است را می‌گیرد و برای کوئری مورد نظر $Q$ نامزدها را تولید می‌کند. از آن‌جایی که می‌دانیم بیشتر از 97% خطاهای املایی در یک فاصله ویرایش ۲ از کوئری موردنظر کاربر قرار دارند، پیشنهاد می‌شود اصلاح کوئری‌های موجود در این فاصله را از $R$ در نظر بگیرید. این راه‌حلی است که توسط Peter Norvig در [این مقاله در مورد اصلاح خطاهای املایی](http://norvig.com/spell-correct.html) پیشنهاد شده است. اگرچه استفاده از یک تولیدکننده‌ی بروت فورس خالص که تمام رشته‌های ممکن با فاصله‌ی ۲ از  $R$ را تولید کند راه معقولی نیست، چون برای هر $R$ با طول غیرناچیز، تعداد نامزدها خیلی زیاد خواهد شد. بنابراین ما باید مدل احتمال زبان و ویرایش را برای تعداد زیادی از نامزدها محاسبه کنیم.\n",
    "\n",
    "#### IV.3.1. تولیدکننده‌ی نامزدها با فضای جستجوی محدود (Candidate Generator with Restricted Search Space)\n",
    "\n",
    "ما می‌توانیم راه‌حل ساده‌ای را پیش بگیریم که با محدود کردن زیاد فضای جستجو در حین تولید کردن نامزدها قابل مدیریت است. راه‌حل‌های معتبر زیادی برای تولید نامزد بهینه وجود دارد، چند ایده‌ی ساده در زیر آمده:\n",
    "  - با بررسی *هر ترم، جداگانه* در رشته کوئری $R$ شروع کنید و تمام ویرایش‌های ممکن که با فاصله ۱ از آن‌ ترم وجود دارند را در نظر بگیرید.\n",
    "  - به یاد داشته باشید که می‌توانید هایفن‌ها (علامت خط تیره) یا اسپیس‌ها را به عنوان عناصر مجموعه‌ی کرکترهای خود در نظر بگیرید. با این کار می‌توانید تعدادی خطای نسبتا رایج را در نظر بگیرید، برای مثال وقتی در میان یک کلمه به اشتباه فاصله می‌افتد یا زمانی که دو ترم در یک کوئری به اشتباه توسط اسپیس جدا می‌شوند و در واقع باید به هم چسبیده باشند.\n",
    "  - هر وقت برای یک ترم ویرایشی را اعمال می‌کنید، مطمئن شوید که ترم ویرایش شده در دیکشنری ظاهر شود. (به خاطر داشته باشید که فرض کردیم تمام لغات در یک کوئری نامزد معتبر در training corpus ما قابل یافت است).\n",
    "  - اگر ویرایش‌های ممکن برای چندترم جدا را تولید کردید، محصول کارتزین این ترم‌ها را برای تولید یک کوئری نامزد کامل که شامل ویرایش‌های چندین ترم است را در نظر بگیرید. (اما فراموش نکنید که فاصله ویرایش شما برای کل کوئری جمعا نباید از ۲ بیشتر شود).\n",
    "  \n",
    "استراتژی‌های ذکر شده در بالا فقط در حد ایده‌ی اولیه‌ هستند و می‌توانند تا مقدار زیادی گسترش یابند یا تغییر کنند. پیشنهاد می‌کنیم چند گزینه‌ی مختلف را بررسی کنید و در گزارش کتبی خود استراتژی نهایی خود را ذکر کنید و این که چگونه کاربری این استراتژی را به مقدار بهینه رساندید. در نظر داشته باشید که **راه‌حل‌هایی که تمام کوئری‌های نامزد در فاصله‌ی مورد نظر را تولید می‌کنند بسیار کند هستند و نمره‌ی کامل نخواهند داشت.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "557738fe",
   "metadata": {
    "id": "557738fe"
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "class CandidateGenerator:\n",
    "    # Alphabet to use for insertion and substitution\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "                'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "                '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                ' ', ',', '.', '-']\n",
    "\n",
    "    def __init__(self, lm, epm):\n",
    "\n",
    "        self.lm = lm\n",
    "        self.epm = epm\n",
    "\n",
    "    def get_num_oov(self, query):\n",
    "        return sum(1 for w in query.strip().split()\n",
    "                   if w not in self.lm.unigram_counts)\n",
    "\n",
    "    def filter_and_yield(self, query, lp):\n",
    "        if query.strip() and self.get_num_oov(query) == 0:\n",
    "            yield query, lp\n",
    "    \n",
    "    def get_score_for_term(self, t):\n",
    "        return lm.get_unigram_logp(t) if ' ' not in t else lm.get_bigram_logp(t.split()[0], t.split()[1]) + lm.get_unigram_logp(t.split()[0])\n",
    "        \n",
    "            \n",
    "    def helper(self, term, check=False, top=2):\n",
    "        #Change and insert\n",
    "        terms = []\n",
    "        heapq.heapify(terms)\n",
    "        for i in range(len(term)+1):\n",
    "            for alpha in CandidateGenerator.alphabet:\n",
    "                if alpha.isdigit():\n",
    "                    continue\n",
    "                \n",
    "                temp = term[:i] + alpha + term[i:]\n",
    "                temp = temp.strip()\n",
    "                score = self.get_score_for_term(temp)\n",
    "                if not check:\n",
    "                    terms.append(temp)\n",
    "                elif check and len(terms) == top:\n",
    "                    heapq.heapreplace(terms, (score, temp))\n",
    "                else:\n",
    "                    heapq.heappush(terms, (score, temp))\n",
    "                \n",
    "                if i == len(term) or alpha == term[i] :\n",
    "                    continue\n",
    "                temp = term[:i] + alpha + term[i+1:]\n",
    "                temp = temp.strip()\n",
    "                score = self.get_score_for_term(temp)\n",
    "                if not check:\n",
    "                    terms.append(temp)\n",
    "                elif check and len(terms) == top:\n",
    "                    heapq.heapreplace(terms, (score, temp))\n",
    "                else:\n",
    "                    heapq.heappush(terms, (score, temp))\n",
    "                \n",
    "                \n",
    "        #delete and swap\n",
    "        for i in range(len(term)):\n",
    "            temp = term[:i] + temp[i+1:]\n",
    "            temp = temp.strip()\n",
    "            score = self.get_score_for_term(temp)\n",
    "            if not check:\n",
    "                terms.append(temp)\n",
    "            elif check and len(terms) == top:\n",
    "                heapq.heapreplace(terms, (score, temp))\n",
    "            else:\n",
    "                heapq.heappush(terms, (score, temp))\n",
    "            if i==len(term)-1:\n",
    "                continue\n",
    "            temp = list(term)\n",
    "            temp[i],temp[i+1] = temp[i+1],temp[i]\n",
    "            temp = ''.join(temp)\n",
    "            temp = temp.strip()\n",
    "            score = self.get_score_for_term(temp)\n",
    "            if not check:\n",
    "                terms.append(temp)\n",
    "            elif check and len(terms) == top:\n",
    "                heapq.heapreplace(terms, (score, temp))\n",
    "            else:\n",
    "                heapq.heappush(terms, (score, temp))\n",
    "        if not check:\n",
    "            return list(set(terms))\n",
    "        if check:\n",
    "            return sorted(set(terms), reverse=True)\n",
    "    \n",
    "    def remove_space(self, query):\n",
    "        words = query.split()\n",
    "        result = []\n",
    "        for i in range(len(words)-1):\n",
    "            temp = words[i] + words[i+1]\n",
    "            tokens = words.copy()\n",
    "            if temp in self.lm.unigram_counts:\n",
    "                tokens[i] = temp\n",
    "                tokens.pop(i+1)\n",
    "                result.append(tokens)\n",
    "        return result\n",
    "        \n",
    "    def get_candidates(self, query):\n",
    "\n",
    "        # Yield the unedited query first\n",
    "        # We provide this line as an example of how to use `self.filter_and_yield`\n",
    "        yield from self.filter_and_yield(query, self.epm.get_edit_logp(query, query))\n",
    "\n",
    "        query_prob = lm.get_query_logp(\" \".join(query))\n",
    "        words = query.strip().split()\n",
    "        queries = [words] + self.remove_space(query)\n",
    "        two_in_one_candidate = []\n",
    "        for i in range(len(words)):\n",
    "            if words[i].isdigit() or len(words[i]) == 1:\n",
    "                continue\n",
    "            terms = self.helper(words[i])\n",
    "            for new_term in terms:\n",
    "                new_query = words.copy()\n",
    "                new_query[i] = new_term\n",
    "                if self.get_num_oov(\" \".join(new_query)) == 0:\n",
    "                    if lm.get_query_logp(\" \".join(new_query))> query_prob:\n",
    "                        queries.append(new_query)\n",
    "                else:\n",
    "                    two_in_one_candidate.append((new_term, i))\n",
    "                \n",
    "                \n",
    "        for new_query in queries:\n",
    "            yield from self.filter_and_yield(\" \".join(new_query), self.epm.get_edit_logp(\" \".join(new_query), query))\n",
    "        two_term_edited_queries = []\n",
    "  \n",
    "        for i in range(len(words) - 1):\n",
    "            for _, new_term in self.helper(term=words[i], check=True):\n",
    "                for j in range(i+1,len(words)):\n",
    "                    for _, new_term2 in self.helper(term=words[j], check=True):\n",
    "                        new_query = words.copy()\n",
    "                        new_query[i] = new_term\n",
    "                        new_query[j] = new_term2\n",
    "                        prob = self.epm.get_edit_logp(words[j], new_term2) + self.epm.get_edit_logp(words[i], new_term)\n",
    "                        new_query = \" \".join(new_query)\n",
    "                        if self.get_num_oov(new_query) == 0:\n",
    "                            two_term_edited_queries.append((new_query,prob))\n",
    "\n",
    "        for q in two_term_edited_queries:\n",
    "            yield from self.filter_and_yield(q[0], q[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13df394",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    می‌توانید تست هایی علاوه بر تست زیر برای ارزیابی اضافه \n",
    "    کنید"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f599f01",
   "metadata": {
    "id": "0f599f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cg = CandidateGenerator(lm, epm)\n",
    "query = 'stanford university'\n",
    "num_candidates = 0\n",
    "did_generate_original = False\n",
    "for candidate, candidate_logp in cg.get_candidates(query):\n",
    "    num_candidates += 1\n",
    "    if candidate == query:\n",
    "        did_generate_original = True\n",
    "        \n",
    "    if cg.get_num_oov(query) != 0:\n",
    "        print(\"You should not generate queries with out-of-vocab terms ('{}' has OOV terms)\".format(candidate))\n",
    "\n",
    "\n",
    "print(num_candidates)\n",
    "print(did_generate_original)\n",
    "### Begin your code\n",
    "\n",
    "### End your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2076f83",
   "metadata": {
    "id": "c2076f83"
   },
   "source": [
    "<div dir='rtl'>\n",
    "\n",
    "\n",
    "### IV.4. امتیازدهنده‌ی نامزدها\n",
    "\n",
    "وظیفه امتیازدهنده‌ی نامزدها این است که شبیه‌ترین کوئری $Q$ را به R پیداکند. این‌کار را با ترکیب مدل زبانی  $P(Q)$ و مدل احتمال ویرایش برای $P(R\\mid Q)$ و تولید‌کننده‌ی نامزدها انجام می‌دهد.\n",
    "$$\n",
    "    Q^{*} = \\arg\\max_{Q_{i}} P(Q_{i}\\mid R) = \\arg\\max_{Q_{i}} P(R\\mid Q_{i}) P(Q_{i}),\n",
    "$$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fd5e0",
   "metadata": {
    "id": "6e4fd5e0"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "#### IV.4.1. امتیازدهنده‌ی نامزدها با وزن‌دهی (Candidate Scorer with Weighting)\n",
    "\n",
    "\n",
    "بعد از انجام این ترکیب، ما از یک پارامتر برای وزن‌دادن جداگانه به این دومدل استفاده می‌کنیم.\n",
    "$$\n",
    "    P(Q\\mid R)\\propto P(R\\mid Q)P(Q)^{\\mu}.\n",
    "$$\n",
    "با $\\mu = 1$ شروع کرده و بعدا مقادیر مختلفی را امتحان کنید تا بهترین نتیجه را بگیرید.\n",
    "کد پایین را کامل کنید تا مصحح غلط املایی با uniform edit cost model ساخته شود \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2de033e",
   "metadata": {
    "id": "c2de033e"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CandidateScorer:\n",
    "\n",
    "    def __init__(self, lm, cg, mu=1.):\n",
    "\n",
    "        self.lm = lm\n",
    "        self.cg = cg\n",
    "        self.mu = mu\n",
    "\n",
    "    def get_score(self, query, log_edit_prob):\n",
    "\n",
    "        return self.mu * self.lm.get_query_logp(query) + log_edit_prob \n",
    "\n",
    "    def correct_spelling(self, r):\n",
    "        max_prob = float('-inf')\n",
    "        result = r\n",
    "        for candidate_query, log_edit_prob in self.cg.get_candidates(r):\n",
    "            probability = self.get_score(candidate_query, log_edit_prob)\n",
    "            if probability > max_prob:\n",
    "                result = candidate_query\n",
    "                max_prob = probability\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "174eb40e",
   "metadata": {
    "id": "174eb40e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building edit probability model...\n",
      "Building candidate generator...\n",
      "Building candidate scorer model...\n",
      "Running spelling corrector...\n",
      "\t'stanfrod university' corrected to 'stanford university'\n",
      "\t'stanford unviersity' corrected to 'stanford university'\n",
      "\t'sanford university' corrected to 'stanford university'\n"
     ]
    }
   ],
   "source": [
    "# Assumes LanguageModel lm was already built above\n",
    "print('Building edit probability model...')\n",
    "epm = UniformEditProbabilityModel()\n",
    "print('Building candidate generator...')\n",
    "cg = CandidateGenerator(lm, epm)\n",
    "print('Building candidate scorer model...')\n",
    "cs = CandidateScorer(lm, cg, mu=1.0)\n",
    "print('Running spelling corrector...')\n",
    "\n",
    "# Add your own queries here to test your spelling corrector\n",
    "# queries = [('sharaf university', ' sharif university'),\n",
    "#            ('sharif university', ' sharif university')\n",
    "#            ]\n",
    "queries = [('stanfrod university', 'stanford university'),\n",
    "           ('stanford unviersity', 'stanford university'),\n",
    "           ('sanford university', 'stanford university')]\n",
    "for query, expected in queries:\n",
    "    corrected = cs.correct_spelling(query)\n",
    "    print(\"\\t'{}' corrected to '{}'\".format(query, corrected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cf3de1",
   "metadata": {
    "id": "a1cf3de1"
   },
   "source": [
    "#### IV.4.2. Dev Set Evaluation (Uniform)\n",
    "\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "حال ما یک تصحیح‌گر غلط املایی اولیه را ساختیم.\n",
    "برای ارزیابی مدل خود, سل‌های زیر را اجرا کنید (در صورت داشتن دقت بالاتر از ۷۸٪, حداقل ۵ و حداکثر ۱۵درصد نمره امتیازی به شما داده می‌شود(در صورتی که گروه‌های کمی به این دقت رسیدند, نمره امتیازی به صورت رقابتی داده‌خواهد شد)). \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05b2639",
   "metadata": {
    "id": "b05b2639"
   },
   "outputs": [],
   "source": [
    "def dev_eval(candidate_scorer, verbose=False):\n",
    "    \"\"\"Evaluate `candidate_scorer` on the dev set.\"\"\"\n",
    "    query_num = 1\n",
    "    yours_correct = 0\n",
    "    google_correct = 0\n",
    "    # Read originals, ground-truths, Google's predictions\n",
    "    dev_dir = 'MIR2-data/dev_set/'\n",
    "    with tqdm(total=455, unit=' queries') as pbar, \\\n",
    "            open(os.path.join(dev_dir, 'queries.txt'), 'r') as query_fh, \\\n",
    "            open(os.path.join(dev_dir, 'gold.txt'), 'r') as gold_fh, \\\n",
    "            open(os.path.join(dev_dir, 'google.txt'), 'r') as google_fh:\n",
    "        while True:\n",
    "            # Read one line\n",
    "            query = query_fh.readline().rstrip('\\n')\n",
    "            if not query:\n",
    "                # Finished all queries\n",
    "                break\n",
    "            corrected = candidate_scorer.correct_spelling(query)\n",
    "            corrected = ' '.join(corrected.split())  # Squash multiple spaces\n",
    "            gold = gold_fh.readline().rstrip('\\n')\n",
    "            google = google_fh.readline().rstrip('\\n')\n",
    "\n",
    "            # Count whether correct\n",
    "            if corrected == gold:\n",
    "                yours_correct += 1\n",
    "            if google == gold:\n",
    "                google_correct += 1\n",
    "\n",
    "            # Print running stats\n",
    "            yours_accuracy = yours_correct / query_num * 100\n",
    "            google_accuracy = google_correct / query_num * 100\n",
    "            if verbose:\n",
    "                print('QUERY {:03d}'.format(query_num))\n",
    "                print('---------')\n",
    "                print('(original):      {}'.format(query))\n",
    "                print('(corrected):     {}'.format(corrected))\n",
    "                print('(google):        {}'.format(google))\n",
    "                print('(gold):          {}'.format(gold))\n",
    "                print('Google accuracy: {}/{} ({:5.2f}%)\\n'\n",
    "                      .format(google_correct, query_num, google_accuracy))\n",
    "                print('Your accuracy:   {}/{} ({:5.2f}%)'\n",
    "                      .format(yours_correct, query_num, yours_accuracy))\n",
    "            \n",
    "            pbar.set_postfix(google='{:5.2f}%'.format(google_accuracy),\n",
    "                             yours='{:5.2f}%'.format(yours_accuracy))\n",
    "            pbar.update()\n",
    "            query_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85dc5ee2",
   "metadata": {
    "id": "85dc5ee2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 455/455 [00:08<00:00, 55.96 queries/s, google=83.08%, yours=81.98%]\n"
     ]
    }
   ],
   "source": [
    "# Set verbose=True for debugging output\n",
    "dev_eval(cs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed4a81",
   "metadata": {
    "id": "55ed4a81"
   },
   "source": [
    "<a id='empirical'></a>\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "##  تصحیح املا با هزینه‌های ویرایش تجربی\n",
    "\n",
    "### V.1. مدل احتمال ویرایش بهبودیافته (Improved Edit Probability Model)\n",
    "\n",
    "\n",
    "</div>\n",
    "<div dir='rtl'>\n",
    "حال که تصحیح‌کننده غلط املایی ما با یک مدل احتمالاتی ویرایش اولیه(edit probability model) به درستی کار می‌کند, برای ویرایش احتمالات به سمت یک رویکرد کاربردی‌تر می‌رویم. برای این بخش و learn کردن این احتمال ویرایش‌ها ما از داده‌ی خطای تجربی که در  \n",
    "`data/training_set/edit1s.txt` قراردارد استفاده می‌کنیم\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d9ccb",
   "metadata": {
    "id": "af0d9ccb"
   },
   "source": [
    "<div dir='rtl'>\n",
    "\n",
    "#### V.1.1. هزینه‌ها‌ی ویرایش تجربی (Empirical Edit Costs) \n",
    "</div>\n",
    "\n",
    "<div dir='rtl'>\n",
    "\n",
    "\n",
    "\n",
    "یک لیست از جفت کوئری‌هایی که فاصله‌یشان از یکدیگر دقیقا ۱ است به شما داده شده است. در قدم اول یک الگوریتم ساده برای تعیین کردن این که کدام ویرایش بخصوص میان دو کوئری در هر جفت وجود دارد پیاده‌سازی کنید. با جمع کردن شمارش تمام ویرایش‌های این‌چنینی در تمام کوئری‌ها احتمال هر ویرایش قابل محاسبه خواهد بود. به عنوان مثال، اگر خواستید تعیین کنید که احتمال جایگزین شدن اشتباهی حرف 'e' با حرف 'a' در یک کوئری چقدر است، باید مقدار زیر را محاسبه کنید:\n",
    "$$\n",
    "    P(\\texttt{sub}[a, e]) = \\frac{\\texttt{count}(\\texttt{sub}[a, e])}{\\texttt{count}(e)}.\n",
    "$$\n",
    "با توجه به این که احتمال عملیات‌های درج و حذف به حروف قبل از حرفی که روی آن عملی انجام می‌شود مشروطند، پس باید راه‌حل مناسبی برای حذف و درج در ابتدای یک لغت ارائه دهید. در نهایت برای رفع مشکل پراکندگی داده‌ها در فایل training روش هموارسازی Laplace add-one را برای احتمالات ویرایش پیاده‌سازی کنید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99ccb999",
   "metadata": {
    "id": "99ccb999"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Edit:\n",
    "\n",
    "    INSERTION = 1\n",
    "    DELETION = 2\n",
    "    TRANSPOSITION = 3\n",
    "    SUBSTITUTION = 4\n",
    "\n",
    "    def __init__(self, edit_type, c1=None, c2=None):\n",
    "\n",
    "        self.edit_type = edit_type\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "\n",
    "class EmpiricalEditProbabilityModel(BaseEditProbabilityModel):\n",
    "\n",
    "    START_CHAR = ''      # Used to indicate start-of-query\n",
    "    NO_EDIT_PROB = 0.92  # Hyperparameter for probability assigned to no-edit\n",
    "\n",
    "    def __init__(self, training_set_path='MIR2-data/training_set/edit1s.txt'):\n",
    "\n",
    "        # Your code needs to initialize all four of these data structures\n",
    "        self.unigram_counts = Counter()  # Maps chars c1 -> count(c1)\n",
    "        self.bigram_counts = Counter()   # Maps tuples (c1, c2) -> count((c1, c2))\n",
    "        self.alphabet_size = 0           # Counts all possible characters\n",
    "\n",
    "        # Maps edit-types -> dict mapping tuples (c1, c2) -> count(edit[c1, c2])\n",
    "        # Example usage: \n",
    "        #   > e = Edit(Edit.SUBSTITUTION, 'a', 'b')\n",
    "        #   > edit_count = self.edit_counts[e.edit_type][(e.c1, e.c2)]\n",
    "        self.edit_counts = {edit_type: Counter()\n",
    "                            for edit_type in (Edit.INSERTION, Edit.DELETION,\n",
    "                                              Edit.SUBSTITUTION, Edit.TRANSPOSITION)}\n",
    "\n",
    "        with open(training_set_path, 'r') as training_set:\n",
    "            for example in tqdm(training_set, total=819722):\n",
    "                edited, original = example.strip().split('\\t')\n",
    "\n",
    "                \n",
    "\n",
    "                original_query = EmpiricalEditProbabilityModel.START_CHAR + original\n",
    "                original_query_list = list(original_query)\n",
    "                self.unigram_counts.update(original_query_list)\n",
    "                temp = []\n",
    "                for i in range(len(original_query_list)-1):\n",
    "                    temp.append((original_query_list[i],original_query_list[i+1]))\n",
    "                self.bigram_counts.update(temp)\n",
    "                edit = self.get_edit(edited, original)\n",
    "                if edit:\n",
    "                    self.edit_counts[edit.edit_type].update([(edit.c1, edit.c2)])\n",
    "\n",
    "            self.alphabet_size = len(self.unigram_counts)\n",
    "                \n",
    "\n",
    "    def get_edit(self, edited, original):\n",
    "\n",
    "        if edited == original:\n",
    "            return None\n",
    "        if len(edited) != len(original):\n",
    "            edited = EmpiricalEditProbabilityModel.START_CHAR + edited\n",
    "            original = EmpiricalEditProbabilityModel.START_CHAR + original \n",
    "            if len(edited)< len(original): \n",
    "                for i in range(1,len(edited)):\n",
    "                    if edited[i]!=original[i]:\n",
    "                        return Edit(Edit.DELETION, original[i], original[i-1])\n",
    "                return Edit(Edit.DELETION, original[-1], original[-2])\n",
    "            else:\n",
    "                for i in range(1,len(original)):\n",
    "                    if edited[i]!=original[i]:\n",
    "                        return Edit(Edit.INSERTION, edited[i], original[i-1])\n",
    "                return Edit(Edit.INSERTION, edited[-1], original[-1])\n",
    "            \n",
    "        else:\n",
    "            number_of_char_in_edited = Counter(list(edited))\n",
    "            number_of_char_in_original = Counter(list(original))\n",
    "            for i in range(len(edited)):\n",
    "                if edited[i]!=original[i]:\n",
    "                    if number_of_char_in_edited == number_of_char_in_original:\n",
    "                        return Edit(Edit.TRANSPOSITION, edited[i], original[i])\n",
    "                    else:\n",
    "                        return Edit(Edit.SUBSTITUTION, edited[i], original[i])\n",
    "            \n",
    "\n",
    "        \n",
    "    def get_edit_logp(self, edited, original):\n",
    "\n",
    "        edit = self.get_edit(edited, original)\n",
    "        log = math.log\n",
    "        \n",
    "        if edit == None:\n",
    "            return math.log(EmpiricalEditProbabilityModel.NO_EDIT_PROB)\n",
    "        x = self.edit_counts[edit.edit_type][(edit.c1,edit.c2)]\n",
    "        if edit.edit_type == Edit.SUBSTITUTION:\n",
    "            # for smoothing we add alphabet size\n",
    "            return log(x+1)-log(self.unigram_counts[edit.c1] + self.alphabet_size)\n",
    "        elif edit.edit_type == Edit.INSERTION:\n",
    "            # for smoothing we add alphabet size\n",
    "            return log(x+1)-log(self.unigram_counts[edit.c1] + self.alphabet_size)\n",
    "        elif edit.edit_type == Edit.DELETION:\n",
    "            # for smoothing we add alphabet size ^2\n",
    "            return log(x+1)-log(self.bigram_counts[(edit.c1,edit.c2)] + self.alphabet_size**2)\n",
    "        else:\n",
    "            # for smoothing we add alphabet size ^2\n",
    "            return log(x+1)-log(self.unigram_counts[(edit.c1,edit.c2)] + self.alphabet_size**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6159e772",
   "metadata": {
    "id": "6159e772"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 819722/819722 [00:11<00:00, 72811.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build spelling corrector for evaluation on the dev set\n",
    "lm = LanguageModel()\n",
    "epm = EmpiricalEditProbabilityModel()\n",
    "cg = CandidateGenerator(lm, epm)\n",
    "cs = CandidateScorer(lm, cg, mu=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92745d20",
   "metadata": {},
   "source": [
    "<div dir='rtl'>\n",
    "     . در صورت داشتن دقت بالاتر از 79٪, ۵ تا ۱۵درصد نمره امتیازی به شما داده می‌شود (در صورتی که گروه‌های کمی به این دقت رسیدند, نمره امتیازی به صورت رقابتی داده‌خواهد شد)\n",
    "    </div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890f3261",
   "metadata": {
    "id": "890f3261"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 455/455 [00:09<00:00, 48.87 queries/s, google=83.08%, yours=84.84%]\n"
     ]
    }
   ],
   "source": [
    "# Set verbose=True for debugging output\n",
    "dev_eval(cs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3a3c5",
   "metadata": {},
   "source": [
    "<a id='written'></a>\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "##  گزارش مکتوب\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "در این بخش انتظار می‌رود که شما گزارشی از کارهای انجام شده در هر تسک - نتایج گرفته شده و ایده‌هایی که استفاده کردید و نیز تغییرات داده شده در کد(در صورت وجود) بنویسید. این بخش ۱۵درصد نمره شما را خواهد داشت\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898ac4e",
   "metadata": {},
   "source": [
    "# بخش ۱.۱\n",
    "در این بخش با شمارش تک تک ترم ها و همچنین شمارش جفت کلمه هایی که پشت هم آمده اند دو شمارنده را ساخته میشود.\n",
    "\n",
    "سپس با روش گفته شده احتمال ها محاسبه میشود."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5115ada",
   "metadata": {},
   "source": [
    "# بخش ۱.۲\n",
    "در این بخش طبق توضیحات کافی است فقط تفاوت را مشاهده کرد و احتمال ها را حساب کرد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13c0f9",
   "metadata": {},
   "source": [
    "# بخش ۱.۳\n",
    "برای تولد کاندیدا ها به ازای هر ترم به وسیله تابع کمک کننده تمام ترم ها با تغییرات ۱ را بدست می اوریم و در هیپ نگه میداریم به همراه احتمال آن\n",
    "\n",
    "در این بخش برای هر ترم به صورت جداگانه ابتدا ترم ها با فاصله یک را بدست می اوریم و جابجا میکنیم و اگر در حالت جدید احتمال از حالت قبل باشد آن را به کوئری های جدید اضافه میکنیم.\n",
    "\n",
    "سپس برای دو ترم در کوئری فعلی این کار را میکنیم که کوئری هایی با فاصله دو بدست بیاوریم. با این تفاوت که چون احتمال باید بر اساس اینکه دو تغییر داریم محاسبه شود احتمال تغییر هر ترم را جمع میکنیم."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa43dda",
   "metadata": {},
   "source": [
    "# بخش ۱.۴\n",
    "میکنیم که چون لگاریتیم میگیریم به صورت جمع در می آید. در نهایت کاندیدا با بیشترین احتمال را به عنوان کوئری صحیح خروجی می دهیم. p(q)p(r|Q) برای احتمال از ضرب"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c63d554",
   "metadata": {},
   "source": [
    "# بخش ۲\n",
    "در این بخش برای هر کاراکتر ابتدا تعداد آن و همچنین تعداد زوج کاراکتر های پشت هم محاسبه میشود.\n",
    "\n",
    "سپس برای بدست اوردن تعداد تغییرات و نوع آن از طول کوئری استفاده میکنیم که اگر برابر نباشید حذف یا درج است و اگر برابر باشد جابجایی یا تغییر است که با حرکت روی رشته محل تغییر و کارکتر های مورد نظر را بدست می آوریم.\n",
    "\n",
    "برای محاسبه احتمال از روش لاپلاس استفاده میکنیم که به صورت احتمال یک و به مخرج به اندازه سایز الفابت اضافه میکنیم. یعنی هر مشاهده را یکی بیشتر در نظر میگیریم.\n",
    "\n",
    "در نهایت نسبت خواسته شده را خروجی میدهیم.\n",
    "\n",
    "لازم به ذکر است که باید برای حالات حذف و جابجایی نحوه دیگری برای محاسبه احتمال بدهیم زیرا برای دوتایی های پشت هم مهم است که چه تعداد از این دوتایی ها داریم."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIR-Phase2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
